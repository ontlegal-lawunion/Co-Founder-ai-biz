# Barge-In Feature

The barge-in feature allows users to interrupt the AI while it's speaking, creating more natural and responsive conversation flow.

## Overview

**What is Barge-In?**  
Barge-in (also called "turn-taking" or "interruption") enables users to interrupt the AI mid-response by simply starting to speak. The AI's audio stops immediately, and the user's new input is processed.

**Why It Matters:**
- Makes conversations feel more natural and human-like
- Reduces frustration when AI gives long responses
- Essential for ADHD users who may need to redirect quickly
- Enables more dynamic, back-and-forth dialogue

---

## How It Works

### Current Implementation

1. **Voice Activity Detection (VAD)**
   - Monitors microphone input continuously during AI speech
   - Detects when user starts speaking (volume above threshold)
   
2. **Smart Triggering**
   - Requires 300ms of sustained voice activity to prevent false positives
   - Filters out coughs, clicks, and background noise
   
3. **Immediate Response**
   - Stops all AI audio playback instantly
   - Sends interrupt signal to backend
   - User's new audio input is processed immediately

4. **Visual Feedback**
   - Blue banner shows "AI is speaking - start talking to interrupt"
   - Banner disappears when AI finishes or is interrupted

### Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   User Speaks   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Voice Activity Detector ‚îÇ (Analyzes audio levels)
‚îÇ   Threshold: 30         ‚îÇ
‚îÇ   Check Interval: 50ms  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº (if AI is speaking)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Sustained Activity?    ‚îÇ (300ms continuous)
‚îÇ   Yes: Trigger barge-in ‚îÇ
‚îÇ   No: Keep monitoring   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Stop AI Audio         ‚îÇ (Client-side)
‚îÇ   Send Interrupt Signal ‚îÇ (To backend)
‚îÇ   Process New Input     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Implementation Details

### Frontend Components

**1. Voice Activity Detector** (`frontend/src/utils/voiceActivityDetection.ts`)
```typescript
// Monitors audio input and detects voice activity
const vad = new VoiceActivityDetector(audioContext, stream, 30);

vad.startListening(() => {
  if (isAISpeaking && sustained > 300ms) {
    handleBargeIn();
  }
}, 50); // Check every 50ms
```

**2. Barge-In Handler** (`frontend/src/App.tsx`)
```typescript
const handleBargeIn = () => {
  // Stop all playing audio sources
  audioSourcesRef.current.forEach(source => source.stop());
  
  // Send interrupt to backend
  ws.send(JSON.stringify({ type: 'interrupt' }));
  
  // Reset state
  setIsAISpeaking(false);
};
```

**3. Audio Playback Tracking**
- Sets `isAISpeaking = true` when AI starts playing audio
- Sets `isAISpeaking = false` when all audio finishes
- VAD only triggers barge-in when `isAISpeaking === true`

### Backend Components

**1. Interrupt Message Handler** (`backend/src/index.ts`)
```typescript
ws.on('message', (message) => {
  // Check if message is JSON (control message)
  if (isJSON(message)) {
    const { type } = JSON.parse(message);
    
    if (type === 'interrupt') {
      // Acknowledge interrupt
      ws.send(JSON.stringify({ 
        type: 'interrupt_acknowledged' 
      }));
      
      // Gemini handles interruption naturally
      // when new audio input arrives
    }
  }
});
```

**2. Natural Interruption**
- Gemini Live API handles interruptions internally
- When user starts speaking, new audio input naturally takes priority
- Backend doesn't need to explicitly stop generation
- System is designed for full-duplex communication

---

## Configuration

### Sensitivity Tuning

Adjust the VAD threshold based on your environment:

```typescript
// In App.tsx, handleStartSession:
vadRef.current = new VoiceActivityDetector(
  inputAudioContextRef.current, 
  stream, 
  30  // ‚Üê Threshold (10-50)
      // 10 = Very sensitive (may trigger on background noise)
      // 30 = Balanced (default)
      // 50 = Less sensitive (requires louder voice)
);
```

### Sustained Activity Duration

Prevent false triggers from quick sounds:

```typescript
const SUSTAINED_ACTIVITY_THRESHOLD = 300; // milliseconds

// User must speak continuously for 300ms to trigger barge-in
// Lower = More responsive, but more false positives
// Higher = Fewer false positives, but less responsive
```

### Check Interval

How often to check for voice activity:

```typescript
vadRef.current.startListening(() => {
  // barge-in logic
}, 50); // ‚Üê Check every 50ms

// 25ms = More responsive, higher CPU usage
// 50ms = Balanced (default)
// 100ms = Less responsive, lower CPU usage
```

---

## Testing Barge-In

### Manual Test Checklist

1. **Start conversation**
   - Click microphone button
   - Ask AI a question that generates a long response
   
2. **Wait for AI to start speaking**
   - Look for blue "AI is speaking" banner
   - Hear audio playing
   
3. **Interrupt mid-response**
   - Start speaking while AI is talking
   - ‚úÖ AI audio should stop within ~100-200ms
   - ‚úÖ Blue banner should disappear
   - ‚úÖ Your new input should be processed
   - ‚úÖ Check console for: "üî¥ Barge-in detected"

4. **Test edge cases**
   - Interrupt at very beginning of response
   - Interrupt near end of response
   - Multiple rapid interruptions
   - Cough/click while AI speaking (should NOT trigger)
   - Background noise (should NOT trigger)

### Console Logging

Monitor barge-in behavior:

```typescript
// Frontend logs:
"‚úì Voice Activity Detection enabled for barge-in"
"üî¥ Barge-in detected - stopping AI audio"

// Backend logs:
"üî¥ Interrupt signal received from client"
"‚úì Interrupt acknowledged"
```

### Debugging

If barge-in isn't working:

**Not Triggering:**
- Check console for VAD initialization
- Verify `isAISpeaking` state is `true`
- Lower threshold (try 20 instead of 30)
- Reduce sustained activity duration (try 200ms)

**Triggering Too Often:**
- Increase threshold (try 40-50)
- Increase sustained activity duration (try 500ms)
- Check for background noise sources

**Audio Not Stopping:**
- Verify `audioSourcesRef` contains sources
- Check browser console for errors
- Ensure `handleBargeIn` is being called

---

## Performance Considerations

### Client-Side Impact

**CPU Usage:**
- VAD checks every 50ms: ~0.5-1% CPU
- Negligible for modern devices
- Can be adjusted based on device capabilities

**Memory:**
- VAD analyser: ~8KB
- Frequency data array: ~256 bytes
- Total overhead: <10KB

**Latency:**
- Detection to audio stop: ~50-150ms
- Faster than human perception threshold
- Feels instantaneous to users

### Network Impact

**Bandwidth:**
- Interrupt signal: ~50 bytes
- Acknowledgment: ~80 bytes
- Total per interruption: ~130 bytes
- Negligible bandwidth usage

---

## Advanced Features

### Future Enhancements

**1. Adaptive Sensitivity**
```typescript
// Auto-adjust threshold based on environment noise
let noiseFloor = calculateNoiseFloor();
let threshold = noiseFloor + 15; // Dynamic threshold
```

**2. Interruption Analytics**
```typescript
// Track how often users interrupt
const analytics = {
  totalInterruptions: 0,
  averageTimeBeforeInterruption: 0,
  mostInterruptedTopics: []
};
```

**3. Graceful Resume**
```typescript
// Allow AI to continue if user stops speaking
if (noActivityFor(2000)) {
  resumeAIResponse();
}
```

**4. Visual Interruption Feedback**
```typescript
// Animate when barge-in triggers
<div className="animate-pulse-once">
  ‚ö° Interrupted
</div>
```

---

## Customization for Other PWAs

### Language Learning App

```typescript
// More lenient barge-in for beginners
const threshold = language === 'beginner' ? 25 : 35;

// Encourage interruption for practice
<p>Try interrupting to practice conversation!</p>
```

### Customer Support Bot

```typescript
// Less aggressive barge-in
const SUSTAINED_ACTIVITY_THRESHOLD = 500; // Wait longer

// Show helpful message
<p>Press spacebar to interrupt</p>
```

### Interview Practice

```typescript
// Disable barge-in during questions
if (mode === 'asking_question') {
  vadRef.current?.stopListening();
} else {
  vadRef.current?.startListening(handleBargeIn);
}
```

---

## Troubleshooting

### Common Issues

**Issue: False positives from background noise**
```typescript
// Solution 1: Increase threshold
vadRef.current = new VoiceActivityDetector(context, stream, 40);

// Solution 2: Increase sustained duration
const SUSTAINED_ACTIVITY_THRESHOLD = 500;
```

**Issue: Barge-in not responsive enough**
```typescript
// Solution 1: Decrease check interval
vadRef.current.startListening(handleBargeIn, 25);

// Solution 2: Decrease sustained duration
const SUSTAINED_ACTIVITY_THRESHOLD = 200;
```

**Issue: Audio doesn't stop completely**
```typescript
// Ensure all sources are tracked
audioSourcesRef.current.add(source);

// Stop all sources explicitly
audioSourcesRef.current.forEach(s => {
  try { s.stop(); } catch(e) {}
});
```

---

## Best Practices

### ‚úÖ DO:

1. **Test with real users** in noisy environments
2. **Provide visual feedback** when AI is speaking
3. **Log interruptions** for debugging
4. **Make threshold configurable** per user
5. **Handle edge cases** gracefully

### ‚ùå DON'T:

1. **Don't use too low threshold** (< 15) - causes false positives
2. **Don't check too frequently** (< 25ms) - wastes CPU
3. **Don't forget cleanup** - destroy VAD on unmount
4. **Don't make it too hard** to interrupt - frustrates users
5. **Don't interrupt critical information** - consider context

---

## Summary

The barge-in feature provides:

‚úÖ **Natural conversation flow** - Interrupt anytime like real conversations  
‚úÖ **Immediate response** - Audio stops within 100-200ms  
‚úÖ **Smart detection** - Filters noise and false positives  
‚úÖ **Visual feedback** - Clear indication when interruption is available  
‚úÖ **Low overhead** - <1% CPU, <10KB memory  
‚úÖ **Configurable** - Adjust sensitivity per use case  

This makes the AI feel more responsive and human-like, especially important for ADHD users who may need to redirect conversations quickly or have difficulty waiting through long responses.

**Ready to use in all PWAs!** üéâ
